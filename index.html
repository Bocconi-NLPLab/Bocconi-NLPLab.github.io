<html>
	<head>
	<h1>papers we have discussed</h1>
	</head>
	<body>

		"Attention Is All You Need" - https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf<br/>

		"Exploring the Utility of Community-Generated Social Media Content for Detecting Depression: An Analytical Study on Instagram" - https://www.jmir.org/2018/12/e11817/pdf<br/>

		"Exponential Family Embeddings" - https://arxiv.org/pdf/1608.00778.pdf<br/>

		"Relational inductive biases, deep learning, and graph networks" - https://arxiv.org/pdf/1806.01261.pdf<br/>

		"Loss in Translation: Learning Bilingual Word Mapping with a Retrieval Criterion" - https://arxiv.org/pdf/1804.07745.pdf<br/>

		"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding" - https://arxiv.org/pdf/1810.04805.pdf<br/>

		"Enquiring Minds: Early Detection of Rumors in Social
		Media from Enquiry Posts" - http://www-personal.umich.edu/~qmei/pub/www2015-zhao.pdf<br/>

		"The Geometry of Culture: Analyzing Meaning through Word Embeddings" - https://arxiv.org/ftp/arxiv/papers/1803/1803.09288.pdf<br/>

		"DeClarE: Debunking Fake News and False Claims
		using Evidence-Aware Deep Learning" - http://aclweb.org/anthology/D18-1003<br/>

		"Towards Robust and Privacy-preserving Text Representations" - http://aclweb.org/anthology/P18-2005<br/>

		"Neural Machine Translation by Jointly Learning to Align and Translate" - https://arxiv.org/pdf/1409.0473.pdf

	</body>
</html>